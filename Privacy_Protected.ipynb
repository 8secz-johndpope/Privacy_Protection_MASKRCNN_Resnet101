{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import coco\n",
    "import utils\n",
    "import model as modellib\n",
    "import time\n",
    "\n",
    "\n",
    "#if we use ImageNet model for any specific classifier\n",
    "'''\n",
    "from keras.applications import InceptionV3\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing.image import img_to_array\n",
    "'''\n",
    "\n",
    "ROOT_DIR = os.getcwd()\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\envs\\gputest\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From G:\\VIP CUP\\Task-2\\Mask\\Mask_RCNN_Video_Privacy\\model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "class InferenceConfig(coco.CocoConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "\n",
    "config = InferenceConfig()\n",
    "\n",
    "#config.display()\n",
    "\n",
    "model = modellib.MaskRCNN(\n",
    "    mode=\"inference\", model_dir=MODEL_DIR, config=config\n",
    ")\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
    "class_names = [\n",
    "    'BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "    'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "    'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "    'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "    'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "    'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "    'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "    'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "    'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "    'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "    'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "    'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main defining function for blurry image\n",
    "def blur_image(img):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        img (numpy.array): RGB image. Contains people. Used as \"read-only\" and will not be modified by this function.\n",
    "        img_background (numpy.array): RGB image. There are no people in this image. \n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    # img_copy will be modified with the pixel manipulations and returned by the function\n",
    "    img_copy = np.copy(img)\n",
    "    \n",
    "    blur_img=cv2.GaussianBlur(img,(37,37),0)  ##BLUR## \n",
    "    \n",
    "    results = model.detect([img], verbose=0)\n",
    "    results = results[0]\n",
    "    \n",
    "    '''\n",
    "    ##NOT NEEDED as it shows image with every classifiers\n",
    "    if display_imgs:\n",
    "        visualize.display_instances(img, results['rois'], results['masks'], results['class_ids'], \n",
    "                                    class_names, results['scores'])\n",
    "    '''\n",
    "    # shape of the masks are (h, w, object_ix)\n",
    "    n_objects_found = len(results['class_ids'])\n",
    "    for ix in range(n_objects_found):\n",
    "        if ((results['class_ids'][ix] == (class_names.index('tv'))) \n",
    "            or (results['class_ids'][ix] == (class_names.index('person'))) or (results['class_ids'][ix] == (class_names.index('laptop'))) \n",
    "            or (results['class_ids'][ix] == (class_names.index('keyboard')))) :      ###for some specific sensitive classes\n",
    "            bbox = results['rois'][ix]\n",
    "            if bbox is not None:\n",
    "                x, y, w, h = bbox          ###get a different image for person face depending on bbox\n",
    "                \n",
    "                p_mask = results['masks'][:, :, ix]       ###get the specific object's mask\n",
    "\n",
    "                # The mask is reduced by 2 pixels in all four directions toensure the object is precisely covered.\n",
    "                ##(NEEDED FOR PRECISION)\n",
    "                padding = 2\n",
    "                p_mask_2 = np.roll(p_mask, -padding, axis=0)\n",
    "                p_mask_3 = np.roll(p_mask, padding, axis=0)\n",
    "                p_mask_4 = np.roll(p_mask, -padding, axis=1)\n",
    "                p_mask_5 = np.roll(p_mask, padding, axis=1)\n",
    "                p_masks = [p_mask, p_mask_2, p_mask_3, p_mask_4, p_mask_5]\n",
    "                p_masks_merged = np.logical_or.reduce(p_masks, axis=0)\n",
    "\n",
    "                other_masks = np.delete(results['masks'], ix, axis=2)\n",
    "                other_masks_merged = np.logical_or.reduce(other_masks, axis=2)\n",
    "\n",
    "                person_mask_minus_others = p_masks_merged & np.logical_not(other_masks_merged)\n",
    "\n",
    "                '''MAIN PROCESSING PART\n",
    "                to blur each frame'''\n",
    "\n",
    "                #img_copy[person_mask_minus_others] = img_background[person_mask_minus_others]   #to make invisible\n",
    "                img_copy[person_mask_minus_others] = blur_img[person_mask_minus_others]\n",
    "\n",
    "    end = time.time()\n",
    "    print('{} seconds to process image'.format(int(end - start)))\n",
    "    \n",
    "    return img_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "1 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n",
      "0 seconds to process image\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0424ba0e7ce6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcapture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         '''\n",
      "\u001b[1;32mG:\\VIP CUP\\Task-2\\Mask\\Mask_RCNN_Video_Privacy\\model.py\u001b[0m in \u001b[0;36mdetect\u001b[1;34m(self, images, verbose)\u001b[0m\n\u001b[0;32m   2501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2502\u001b[0m         \u001b[1;31m# Mold inputs to format expected by the neural network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2503\u001b[1;33m         \u001b[0mmolded_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_metas\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwindows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmold_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2505\u001b[0m         \u001b[1;31m# Validate image sizes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\VIP CUP\\Task-2\\Mask\\Mask_RCNN_Video_Privacy\\model.py\u001b[0m in \u001b[0;36mmold_inputs\u001b[1;34m(self, images)\u001b[0m\n\u001b[0;32m   2399\u001b[0m                 \u001b[0mmin_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMAGE_MIN_SCALE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2400\u001b[0m                 \u001b[0mmax_dim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMAGE_MAX_DIM\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2401\u001b[1;33m                 mode=self.config.IMAGE_RESIZE_MODE)\n\u001b[0m\u001b[0;32m   2402\u001b[0m             \u001b[0mmolded_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmold_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmolded_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2403\u001b[0m             \u001b[1;31m# Build image_meta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mG:\\VIP CUP\\Task-2\\Mask\\Mask_RCNN_Video_Privacy\\mrcnn\\utils.py\u001b[0m in \u001b[0;36mresize_image\u001b[1;34m(image, min_dim, max_dim, min_scale, mode)\u001b[0m\n\u001b[0;32m    419\u001b[0m     \"\"\"\n\u001b[0;32m    420\u001b[0m     \u001b[1;31m# Keep track of image dtype and return results in the same dtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 421\u001b[1;33m     \u001b[0mimage_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    422\u001b[0m     \u001b[1;31m# Default window (y1, x1, y2, x2) and default scale == 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m     \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \"\"\"\n",
    "        test everything\n",
    "    \"\"\"\n",
    "    capture = cv2.VideoCapture('G:\\VIP CUP\\Task-2\\Mask\\Mask_RCNN_Video_Privacy\\mini_subject_2_wave.mp4')\n",
    "\n",
    "    while True:\n",
    "        ret, frame = capture.read()\n",
    "        results = model.detect([frame], verbose=0)\n",
    "        r = results[0]\n",
    "        '''\n",
    "        frame = display_instances(\n",
    "            frame, r['rois'], r['masks'], r['class_ids'], class_names, r['scores']\n",
    "        )\n",
    "        '''\n",
    "        img_processed = blur_image(frame)\n",
    "        cv2.imshow('frame',img_processed)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
