{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "os.chdir('F:\\VIP CUP\\VIP_CUP_Task2')\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import coco\n",
    "import utils\n",
    "import model as modellib\n",
    "import time\n",
    "\n",
    "\n",
    "#if we use ImageNet model for any specific classifier\n",
    "'''\n",
    "from keras.applications import InceptionV3\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing.image import img_to_array\n",
    "'''\n",
    "\n",
    "ROOT_DIR = os.getcwd()\n",
    "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "if not os.path.exists(COCO_MODEL_PATH):\n",
    "    utils.download_trained_weights(COCO_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\dell\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From F:\\VIP CUP\\VIP_CUP_Task2\\model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "class InferenceConfig(coco.CocoConfig):\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "\n",
    "config = InferenceConfig()\n",
    "\n",
    "#config.display()\n",
    "\n",
    "model = modellib.MaskRCNN(\n",
    "    mode=\"inference\", model_dir=MODEL_DIR, config=config\n",
    ")\n",
    "model.load_weights(COCO_MODEL_PATH, by_name=True)\n",
    "class_names = [\n",
    "    'BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "    'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "    'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "    'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "    'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "    'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "    'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "    'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "    'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "    'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "    'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "    'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "    'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_from_dir(dir):\n",
    "    temp=os.listdir(dir)   #give input directory\n",
    "    video=[]\n",
    "    for i in temp:\n",
    "        if(i.endswith('.MP4')):\n",
    "            video.append(i)\n",
    "    return video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main defining function for blurry image\n",
    "def blur_image(img):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        img (numpy.array): RGB image. Contains people. Used as \"read-only\" and will not be modified by this function.\n",
    "        img_background (numpy.array): RGB image. There are no people in this image. \n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    \n",
    "    # img_copy will be modified with the pixel manipulations and returned by the function\n",
    "    img_copy = np.copy(img)\n",
    "    \n",
    "    blur_img=cv2.GaussianBlur(img,(45,45),0)  ##BLUR## \n",
    "    \n",
    "    results = model.detect([img], verbose=0)\n",
    "    results = results[0]\n",
    "    \n",
    "    '''\n",
    "    ##NOT NEEDED as it shows image with every classifiers\n",
    "    if display_imgs:\n",
    "        visualize.display_instances(img, results['rois'], results['masks'], results['class_ids'], \n",
    "                                    class_names, results['scores'])\n",
    "    '''\n",
    "    # shape of the masks are (h, w, object_ix)\n",
    "    n_objects_found = len(results['class_ids'])\n",
    "    for ix in range(n_objects_found):\n",
    "        if ((results['class_ids'][ix] == (class_names.index('tv'))) \n",
    "            or (results['class_ids'][ix] == (class_names.index('person'))) or (results['class_ids'][ix] == (class_names.index('laptop'))) \n",
    "            or (results['class_ids'][ix] == (class_names.index('keyboard'))) \n",
    "            or (results['class_ids'][ix] == (class_names.index('cell phone')))\n",
    "           or (results['class_ids'][ix] == (class_names.index('toilet')))) :      ###for some specific sensitive classes\n",
    "            bbox = results['rois'][ix]\n",
    "            if bbox is not None:\n",
    "                x, y, w, h = bbox          ###get a different image for person face depending on bbox\n",
    "                \n",
    "                p_mask = results['masks'][:, :, ix]       ###get the specific object's mask\n",
    "\n",
    "                # The mask is reduced by 1 pixels in all four directions toensure the object is precisely covered.\n",
    "                ##(NEEDED FOR PRECISION)\n",
    "                padding = 1\n",
    "                p_mask_2 = np.roll(p_mask, -padding, axis=0)\n",
    "                p_mask_3 = np.roll(p_mask, -padding, axis=0)\n",
    "                p_mask_4 = np.roll(p_mask, -padding, axis=1)\n",
    "                p_mask_5 = np.roll(p_mask, -padding, axis=1)\n",
    "                p_masks = [p_mask, p_mask_2, p_mask_3, p_mask_4, p_mask_5]\n",
    "                p_masks_merged = np.logical_or.reduce(p_masks, axis=0)\n",
    "\n",
    "                other_masks = np.delete(results['masks'], ix, axis=2)\n",
    "                other_masks_merged = np.logical_or.reduce(other_masks, axis=2)\n",
    "\n",
    "                person_mask_minus_others = p_masks_merged & np.logical_not(other_masks_merged)\n",
    "\n",
    "                '''MAIN PROCESSING PART\n",
    "                to blur each frame'''\n",
    "\n",
    "                #img_copy[person_mask_minus_others] = img_background[person_mask_minus_others]   #to make invisible\n",
    "                img_copy[person_mask_minus_others] = blur_img[person_mask_minus_others]\n",
    "\n",
    "    end = time.time()\n",
    "    print('{} seconds to process image'.format(int(end - start)))\n",
    "    \n",
    "    return img_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12_21_chat.MP4\n",
      "14 seconds to process image\n",
      "13 seconds to process image\n",
      "14 seconds to process image\n",
      "13 seconds to process image\n",
      "14 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "14 seconds to process image\n",
      "13 seconds to process image\n",
      "14 seconds to process image\n",
      "13 seconds to process image\n",
      "14 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "14 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "14 seconds to process image\n",
      "14 seconds to process image\n",
      "14 seconds to process image\n",
      "13 seconds to process image\n",
      "14 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "1_24_shake.MP4\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "14 seconds to process image\n",
      "15 seconds to process image\n",
      "14 seconds to process image\n",
      "13 seconds to process image\n",
      "14 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "14 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "14 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "13 seconds to process image\n",
      "14 seconds to process image\n",
      "13 seconds to process image\n",
      "14 seconds to process image\n",
      "13 seconds to process image\n",
      "14 seconds to process image\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    cur_dir=os.getcwd()\n",
    "    input_path=os.path.join(cur_dir,'nextbatchRun')         #whatever test_directory is named\n",
    "    video=video_from_dir(input_path)\n",
    "    for j in range(len(video)):\n",
    "        print(video[j])  \n",
    "        capture = cv2.VideoCapture(os.path.join(input_path,video[j]))\n",
    "        fps = capture.get(cv2.CAP_PROP_FPS)\n",
    "        size = (\n",
    "        int(capture.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
    "        int(capture.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        )\n",
    "        codec = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "        os.chdir(os.path.join(cur_dir,'output'))          #whatever protected saved data folder name is \n",
    "        output = cv2.VideoWriter(video[j], codec, fps, size)\n",
    "        ret, frame = capture.read()\n",
    "        while(ret):\n",
    "            results = model.detect([frame], verbose=0)\n",
    "            r = results[0]\n",
    "            img_processed = blur_image(frame)\n",
    "            output.write(img_processed)\n",
    "            #cv2.imshow('frame',img_processed)\n",
    "            if cv2.waitKey(0) & 0xFF == ord('q'):\n",
    "                break\n",
    "            ret, frame = capture.read()\n",
    "\n",
    "        capture.release()\n",
    "        output.release()\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
